{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 16:46:54.941500: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import tensorflow.keras.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = np.load(\"./cleaned_data/small/x_train.npy\")\n",
    "y_train = np.load(\"./cleaned_data/small/y_train.npy\")\n",
    "train_mu = np.load(\"./cleaned_data/small/train_mu.npy\")\n",
    "train_std = np.load(\"./cleaned_data/small/train_std.npy\")\n",
    "x_val = np.load(\"./cleaned_data/small/x_val.npy\")\n",
    "y_val= np.load(\"./cleaned_data/small/y_val.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0., -1.],\n",
       "       [ 1.,  0., -1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [no sack, sack, time to sack]\n",
    "y_train[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    return bce(y_true[:,0:-1], y_pred[:,0:-1]) + mse(y_true[:,-1], y_pred[:,-1])\n",
    "\n",
    "def bce_metric(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_true[:,0:-1], y_pred[:,0:-1], from_logits=False))\n",
    "\n",
    "def mse_metric(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred[:,-1] - y_true[:,-1]), axis=-1)\n",
    "\n",
    "# https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1] * y_pred[:,1], 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true[:,1], 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1] * y_pred[:,1], 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred[:,1], 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nModel\\n\\nhow cropping layer works - https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-cropping-layers-with-keras.md\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Model\n",
    "\n",
    "how cropping layer works - https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-cropping-layers-with-keras.md\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Output:\n",
    "[prob of no sack, prob of sack, time till sack]\n",
    "\n",
    "If predict no sack, doesn't matter what time is (recorded as -1 in training data)\n",
    "'''\n",
    "\n",
    "def createModel(input_shape = (23,7)):\n",
    "    \n",
    "    X = tfl.Input(input_shape)  # define the input to the model\n",
    "    flat = tfl.Flatten(input_shape=(23, 7))(X)     # Flatten to pass into linear layers\n",
    "    #d1 = tfl.Dense(30, activation='relu')(flat)\n",
    "    d3 = tfl.Dense(3,activation=None)(flat)\n",
    "    \n",
    "    # have layer (batch_size, 3). Want to take (b, [0,1]) and turn them into probabilities, and keep (b, [2]) as time\n",
    "    # https://datascience.stackexchange.com/questions/86740/how-to-slice-an-input-in-keras\n",
    "    intermediate = tfl.Reshape((3,1), input_shape=(3,))(d3)\n",
    "    \n",
    "    probs = tfl.Cropping1D(cropping=(0,1))(intermediate)\n",
    "    probs = tfl.Reshape((2,), input_shape=(2,1))(probs)\n",
    "    probs = tfl.Activation('softmax')(probs)\n",
    "    \n",
    "    time = tfl.Cropping1D(cropping=(2,0))(intermediate)\n",
    "    time = tfl.Reshape((1,), input_shape=(1,1))(time)\n",
    "    \n",
    "    # concatenate the probabilities and predicted_time_to_sack back into one layer\n",
    "    out = tfl.Concatenate(axis=-1)([probs, time])\n",
    "    \n",
    "    model = Model(inputs=X, outputs=out)        # create model\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 23, 7)]      0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 161)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            486         ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 3, 1)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " cropping1d (Cropping1D)        (None, 2, 1)         0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 2)            0           ['cropping1d[0][0]']             \n",
      "                                                                                                  \n",
      " cropping1d_1 (Cropping1D)      (None, 1, 1)         0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 2)            0           ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1)            0           ['cropping1d_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3)            0           ['activation[0][0]',             \n",
      "                                                                  'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 486\n",
      "Trainable params: 486\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 16:47:02.251834: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = createModel()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPS = 1e-07\n",
    "\n",
    "opt = optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    epsilon=EPS)\n",
    "\n",
    "model.compile(loss = my_loss, optimizer = opt, metrics = [metrics.CategoricalAccuracy(), bce_metric, mse_metric, recall, precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better optimizer\n",
    "\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=LEARNING_RATE,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "scheduled_opt = optimizers.Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    epsilon=EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "188/188 [==============================] - 2s 2ms/step - loss: 1.8754 - categorical_accuracy: 0.8920 - bce_metric: 0.2937 - mse_metric: 1.5753 - recall: 0.0129 - precision: 0.0161 \n",
      "Epoch 2/50\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.2808 - categorical_accuracy: 0.9396 - bce_metric: 0.2490 - mse_metric: 1.0408 - recall: 0.0011 - precision: 0.0053\n",
      "Epoch 3/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.1211 - categorical_accuracy: 0.9409 - bce_metric: 0.2324 - mse_metric: 0.8847 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 4/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0689 - categorical_accuracy: 0.9412 - bce_metric: 0.2271 - mse_metric: 0.8526 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 5/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0463 - categorical_accuracy: 0.9411 - bce_metric: 0.2229 - mse_metric: 0.8420 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 6/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0380 - categorical_accuracy: 0.9412 - bce_metric: 0.2194 - mse_metric: 0.8146 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 7/50\n",
      "188/188 [==============================] - 0s 1ms/step - loss: 1.0264 - categorical_accuracy: 0.9412 - bce_metric: 0.2198 - mse_metric: 0.8079 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 8/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0224 - categorical_accuracy: 0.9412 - bce_metric: 0.2170 - mse_metric: 0.8016 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 9/50\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 1.0201 - categorical_accuracy: 0.9412 - bce_metric: 0.2166 - mse_metric: 0.7999 - recall: 0.0013 - precision: 0.0053\n",
      "Epoch 10/50\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 1.0142 - categorical_accuracy: 0.9412 - bce_metric: 0.2157 - mse_metric: 0.7945 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 11/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0110 - categorical_accuracy: 0.9412 - bce_metric: 0.2150 - mse_metric: 0.7923 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 12/50\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 1.0092 - categorical_accuracy: 0.9412 - bce_metric: 0.2154 - mse_metric: 0.7903 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 13/50\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 1.0094 - categorical_accuracy: 0.9412 - bce_metric: 0.2173 - mse_metric: 0.8003 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 14/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0098 - categorical_accuracy: 0.9412 - bce_metric: 0.2153 - mse_metric: 0.7909 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 15/50\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 1.0077 - categorical_accuracy: 0.9412 - bce_metric: 0.2164 - mse_metric: 0.8033 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 16/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0084 - categorical_accuracy: 0.9412 - bce_metric: 0.2151 - mse_metric: 0.7898 - recall: 0.0027 - precision: 0.0053 \n",
      "Epoch 17/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0073 - categorical_accuracy: 0.9412 - bce_metric: 0.2151 - mse_metric: 0.7883 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 18/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0055 - categorical_accuracy: 0.9412 - bce_metric: 0.2142 - mse_metric: 0.7875 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 19/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0080 - categorical_accuracy: 0.9412 - bce_metric: 0.2148 - mse_metric: 0.7896 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 20/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0025 - categorical_accuracy: 0.9412 - bce_metric: 0.2139 - mse_metric: 0.7852 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 21/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0061 - categorical_accuracy: 0.9412 - bce_metric: 0.2165 - mse_metric: 0.8413 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 22/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0077 - categorical_accuracy: 0.9412 - bce_metric: 0.2138 - mse_metric: 0.7899 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 23/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0078 - categorical_accuracy: 0.9412 - bce_metric: 0.2152 - mse_metric: 0.7893 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 24/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0068 - categorical_accuracy: 0.9412 - bce_metric: 0.2143 - mse_metric: 0.7888 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 25/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0021 - categorical_accuracy: 0.9412 - bce_metric: 0.2137 - mse_metric: 0.7848 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 26/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0015 - categorical_accuracy: 0.9412 - bce_metric: 0.2137 - mse_metric: 0.7840 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 27/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.9994 - categorical_accuracy: 0.9412 - bce_metric: 0.2150 - mse_metric: 0.7954 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 28/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0029 - categorical_accuracy: 0.9412 - bce_metric: 0.2161 - mse_metric: 0.7877 - recall: 0.0027 - precision: 0.0053\n",
      "Epoch 29/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0059 - categorical_accuracy: 0.9412 - bce_metric: 0.2144 - mse_metric: 0.7879 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 30/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0019 - categorical_accuracy: 0.9412 - bce_metric: 0.2158 - mse_metric: 0.7932 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 31/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0070 - categorical_accuracy: 0.9412 - bce_metric: 0.2142 - mse_metric: 0.7891 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 32/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0023 - categorical_accuracy: 0.9412 - bce_metric: 0.2169 - mse_metric: 0.8095 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 33/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0025 - categorical_accuracy: 0.9411 - bce_metric: 0.2137 - mse_metric: 0.7855 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 34/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0028 - categorical_accuracy: 0.9412 - bce_metric: 0.2153 - mse_metric: 0.7957 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 35/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0033 - categorical_accuracy: 0.9411 - bce_metric: 0.2136 - mse_metric: 0.7858 - recall: 0.0018 - precision: 0.0053 \n",
      "Epoch 36/50\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 1.0005 - categorical_accuracy: 0.9411 - bce_metric: 0.2132 - mse_metric: 0.7837 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 37/50\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 1.0028 - categorical_accuracy: 0.9411 - bce_metric: 0.2138 - mse_metric: 0.7855 - recall: 0.0013 - precision: 0.0053\n",
      "Epoch 38/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0024 - categorical_accuracy: 0.9412 - bce_metric: 0.2132 - mse_metric: 0.7855 - recall: 0.0013 - precision: 0.0053\n",
      "Epoch 39/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0015 - categorical_accuracy: 0.9412 - bce_metric: 0.2133 - mse_metric: 0.7845 - recall: 0.0018 - precision: 0.0053   \n",
      "Epoch 40/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0023 - categorical_accuracy: 0.9412 - bce_metric: 0.2140 - mse_metric: 0.7851 - recall: 0.0053 - precision: 0.0053  \n",
      "Epoch 41/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0041 - categorical_accuracy: 0.9411 - bce_metric: 0.2138 - mse_metric: 0.7867 - recall: 0.0044 - precision: 0.0106    \n",
      "Epoch 42/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0031 - categorical_accuracy: 0.9412 - bce_metric: 0.2143 - mse_metric: 0.7864 - recall: 0.0053 - precision: 0.0053\n",
      "Epoch 43/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0031 - categorical_accuracy: 0.9412 - bce_metric: 0.2159 - mse_metric: 0.7961 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 44/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0001 - categorical_accuracy: 0.9407 - bce_metric: 0.2137 - mse_metric: 0.7844 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 45/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0036 - categorical_accuracy: 0.9412 - bce_metric: 0.2133 - mse_metric: 0.7864 - recall: 0.0053 - precision: 0.0053  \n",
      "Epoch 46/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0015 - categorical_accuracy: 0.9411 - bce_metric: 0.2139 - mse_metric: 0.7846 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 47/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0050 - categorical_accuracy: 0.9412 - bce_metric: 0.2149 - mse_metric: 0.7897 - recall: 0.0018 - precision: 0.0053\n",
      "Epoch 48/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0005 - categorical_accuracy: 0.9411 - bce_metric: 0.2133 - mse_metric: 0.7837 - recall: 0.0013 - precision: 0.0053    \n",
      "Epoch 49/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0034 - categorical_accuracy: 0.9411 - bce_metric: 0.2130 - mse_metric: 0.7865 - recall: 0.0018 - precision: 0.0053\n",
      "Epoch 50/50\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 1.0009 - categorical_accuracy: 0.9414 - bce_metric: 0.2150 - mse_metric: 0.7902 - recall: 0.0027 - precision: 0.0053\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 50\n",
    "history = model.fit(x_train[:,:,4:], y_train, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of training plays with no sack = 0.941\n"
     ]
    }
   ],
   "source": [
    "train_no_sack = np.round(np.sum(y_train[:,0])/len(y_train), 3)\n",
    "print(f\"Percentage of training plays with no sack = {train_no_sack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.9999297e-01,  7.0068982e-06, -1.2895460e+00],\n",
       "       [ 9.8548108e-01,  1.4518979e-02, -8.9697844e-01],\n",
       "       [ 9.9924672e-01,  7.5329869e-04, -9.7019309e-01],\n",
       "       [ 9.9999297e-01,  6.9956409e-06, -1.0302030e+00],\n",
       "       [ 9.9977845e-01,  2.2151478e-04, -9.6254176e-01]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:5,:,4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>bce_metric</th>\n",
       "      <th>mse_metric</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.070431</td>\n",
       "      <td>0.996328</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.067657</td>\n",
       "      <td>0.840426</td>\n",
       "      <td>0.840426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.065897</td>\n",
       "      <td>0.996662</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.062717</td>\n",
       "      <td>0.855053</td>\n",
       "      <td>0.856383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.064973</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.062067</td>\n",
       "      <td>0.844858</td>\n",
       "      <td>0.845745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.064042</td>\n",
       "      <td>0.996495</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.061303</td>\n",
       "      <td>0.869681</td>\n",
       "      <td>0.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.996829</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.058505</td>\n",
       "      <td>0.849734</td>\n",
       "      <td>0.851064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  categorical_accuracy  bce_metric  mse_metric    recall  \\\n",
       "45  0.070431              0.996328    0.002741    0.067657  0.840426   \n",
       "46  0.065897              0.996662    0.003180    0.062717  0.855053   \n",
       "47  0.064973              0.995994    0.002808    0.062067  0.844858   \n",
       "48  0.064042              0.996495    0.002801    0.061303  0.869681   \n",
       "49  0.060942              0.996829    0.002549    0.058505  0.849734   \n",
       "\n",
       "    precision  \n",
       "45   0.840426  \n",
       "46   0.856383  \n",
       "47   0.845745  \n",
       "48   0.872340  \n",
       "49   0.851064  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of validation plays with no sack = 0.947\n"
     ]
    }
   ],
   "source": [
    "num_no_sack = np.round(np.sum(y_val[:,0])/len(y_val), 3)\n",
    "print(f\"Percentage of validation plays with no sack = {num_no_sack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 - 1s - loss: 0.8695 - categorical_accuracy: 0.9470 - bce_metric: 0.2117 - mse_metric: 0.6451 - recall: 0.0000e+00 - precision: 0.0000e+00 - 876ms/epoch - 21ms/step\n"
     ]
    }
   ],
   "source": [
    "val_loss, cat_acc, val_bce, val_mse, val_recall, val_precision = model.evaluate(x_val[:,:,4:], y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss = 0.8695151805877686\n",
      "categorical accuracy = 0.9470404982566833\n",
      "val_bce = 0.21168415248394012\n",
      "val_mse = 0.6450503468513489\n",
      "val_recall = 0.0\n",
      "val_precision = 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"val loss = {val_loss}\")\n",
    "print(f\"categorical accuracy = {cat_acc}\")\n",
    "print(f\"val_bce = {val_bce}\")\n",
    "print(f\"val_mse = {val_mse}\")\n",
    "print(f\"val_recall = {val_recall}\")\n",
    "print(f\"val_precision = {val_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.98357046, 0.99988365, 0.9999479 , ..., 0.9999821 , 0.99990845,\n",
       "       0.9998735 ], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_val[:,:,4:])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kdnuggets.com/2021/02/saving-loading-models-tensorflow.html\n",
    "\n",
    "model_string = f\"models/third_model/weights_epochs{NUM_EPOCHS}\"\n",
    "model.save_weights(model_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bdb_2023')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64e913be5900ee3bfd48533456727a82d0e0b84d6c12de93770bb09b0509b267"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
