{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-30 20:48:07.155418: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "feature_arr = np.load(\"./cleaned_data/feature_arr_ids.npy\")\n",
    "target_arr = np.load(\"./cleaned_data/target_arr_ids.npy\")\n",
    "\n",
    "np.nan_to_num(feature_arr, copy=False, nan=0)\n",
    "np.nan_to_num(target_arr, copy=False, nan=0)\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(feature_arr.reshape(feature_arr.shape[0], -1)).sort_values([0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_x = feature_arr.reshape(feature_arr.shape[0], -1)\n",
    "\n",
    "#print(f\"Shape of dataframe = {df.shape}\")\n",
    "#print(f\"70% of length = {df.shape[0]*.7}\")\n",
    "#print(f\"15% of length = {df.shape[0]*.15}\")\n",
    "\n",
    "# training set will start at. Pick these values so at the start of a new play\n",
    "train_index_end = 196648\n",
    "val_index_end = 238779\n",
    "\n",
    "x_train = reshaped_x[0:train_index_end, :].reshape(-1, feature_arr.shape[1], feature_arr.shape[2])\n",
    "x_val = reshaped_x[train_index_end:val_index_end, :].reshape(-1, feature_arr.shape[1], feature_arr.shape[2])\n",
    "x_test = reshaped_x[val_index_end:, :].reshape(-1, feature_arr.shape[1], feature_arr.shape[2])\n",
    "\n",
    "y_train = target_arr[0:train_index_end]\n",
    "y_val = target_arr[train_index_end:val_index_end]\n",
    "y_test = target_arr[val_index_end:]\n",
    "\n",
    "\n",
    "\n",
    "#df.iloc[train_index_start+42130:train_index_start+42142+10, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 2.0210909e+09  9.7000000e+01  6.0000000e+00  2.5511000e+04\n",
      "    1.0000000e+00  8.2360000e+01  2.3900000e+00  3.5000000e-01\n",
      "    5.3000000e-01  5.4420000e+01  1.9272000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  3.5481000e+04\n",
      "    1.0000000e+00  7.8350000e+01 -2.6900000e+00  1.2000000e+00\n",
      "    1.7800000e+00  3.4897000e+02  3.3346000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  3.5634000e+04\n",
      "    1.0000000e+00  7.8960000e+01 -1.0120000e+01  4.8000000e-01\n",
      "    2.6100000e+00  2.3750000e+01  3.2453000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  3.9985000e+04\n",
      "    1.0000000e+00  8.2450000e+01  4.3800000e+00  4.0000000e-02\n",
      "    4.0000000e-02  1.2300000e+00  3.4376000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.0151000e+04\n",
      "    1.0000000e+00  7.7900000e+01  2.6300000e+00  5.1000000e-01\n",
      "    1.9800000e+00  3.1828000e+02  2.1834000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.1233000e+04\n",
      "    1.0000000e+00  7.7990000e+01  1.0450000e+01  0.0000000e+00\n",
      "    0.0000000e+00  3.9280000e+01  2.7476000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.1263000e+04\n",
      "    2.0000000e+00  7.6700000e+01  7.7600000e+00  9.6000000e-01\n",
      "    9.0000000e-01  2.2648000e+02  1.9876000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.2377000e+04\n",
      "    1.0000000e+00  7.8620000e+01 -2.7000000e-01  8.5000000e-01\n",
      "    2.9000000e+00  5.5190000e+01  1.9352000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.2403000e+04\n",
      "    2.0000000e+00  7.6100000e+01 -5.9800000e+00  3.7000000e-01\n",
      "    2.4400000e+00  1.8877000e+02  1.5775000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.2404000e+04\n",
      "    1.0000000e+00  7.8070000e+01  1.0000000e+00  0.0000000e+00\n",
      "    1.5000000e-01  1.7080000e+01  1.6084000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.3306000e+04\n",
      "    2.0000000e+00  7.5320000e+01 -2.7000000e+00  3.9000000e-01\n",
      "    2.4000000e-01  1.7646000e+02  7.7480000e+01]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.3478000e+04\n",
      "    2.0000000e+00  7.6390000e+01 -1.0970000e+01  1.7000000e-01\n",
      "    1.4000000e-01  2.0595000e+02  3.2877000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.4896000e+04\n",
      "    1.0000000e+00  7.9840000e+01 -8.4400000e+00  2.9800000e+00\n",
      "    1.9300000e+00  3.0740000e+01  7.9400000e+01]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.4904000e+04\n",
      "    2.0000000e+00  7.5390000e+01 -9.7100000e+00  2.5400000e+00\n",
      "    1.4600000e+00  3.4923000e+02  8.9450000e+01]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.4955000e+04\n",
      "    2.0000000e+00  7.6650000e+01  1.4700000e+00  5.6000000e-01\n",
      "    2.4200000e+00  1.5327000e+02  1.9842000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.4962000e+04\n",
      "    2.0000000e+00  6.1010000e+01 -5.3000000e-01  1.1700000e+00\n",
      "    1.2100000e+00  2.1325000e+02  1.0000000e+01]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.6163000e+04\n",
      "    1.0000000e+00  7.8590000e+01  4.0200000e+00  3.0000000e-02\n",
      "    5.3000000e-01  1.6860000e+01  2.1388000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  4.7996000e+04\n",
      "    2.0000000e+00  7.1930000e+01  4.2400000e+00  1.2500000e+00\n",
      "    1.0500000e+00  1.9061000e+02  1.1721000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  5.2421000e+04\n",
      "    1.0000000e+00  7.8890000e+01  5.3400000e+00  3.3000000e-01\n",
      "    1.2500000e+00  3.2453000e+02  1.2191000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  5.2459000e+04\n",
      "    2.0000000e+00  7.6650000e+01  1.0770000e+01  9.0000000e-01\n",
      "    1.8000000e-01  1.9088000e+02  1.0913000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  5.3441000e+04\n",
      "    2.0000000e+00  7.6320000e+01  4.7200000e+00  3.6000000e-01\n",
      "    2.8500000e+00  1.8716000e+02  2.2678000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  5.3504000e+04\n",
      "    2.0000000e+00  7.6300000e+01 -2.0000000e-02  3.0000000e-02\n",
      "    1.8000000e-01  3.0186000e+02  2.5584000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  6.0000000e+00  0.0000000e+00\n",
      "    3.0000000e+00  7.8440000e+01  2.7300000e+00  2.5200000e+00\n",
      "    1.0030000e+01  0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " [[ 2.0210909e+09  9.7000000e+01  7.0000000e+00  2.5511000e+04\n",
      "    1.0000000e+00  8.2440000e+01  2.3900000e+00  5.4000000e-01\n",
      "    1.0500000e+00  4.7490000e+01  1.8295000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  3.5481000e+04\n",
      "    1.0000000e+00  7.8250000e+01 -2.7100000e+00  1.5600000e+00\n",
      "    2.1900000e+00  3.5237000e+02  3.2670000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  3.5634000e+04\n",
      "    1.0000000e+00  7.8900000e+01 -1.0170000e+01  9.2000000e-01\n",
      "    3.9200000e+00  2.1770000e+01  3.2235000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  3.9985000e+04\n",
      "    1.0000000e+00  8.2410000e+01  4.3400000e+00  9.0000000e-02\n",
      "    6.0000000e-02  3.5607000e+02  3.1994000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.0151000e+04\n",
      "    1.0000000e+00  7.7970000e+01  2.5900000e+00  7.9000000e-01\n",
      "    2.1300000e+00  3.2321000e+02  2.1504000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.1233000e+04\n",
      "    1.0000000e+00  7.7980000e+01  1.0440000e+01  0.0000000e+00\n",
      "    0.0000000e+00  3.9280000e+01  2.9329000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.1263000e+04\n",
      "    2.0000000e+00  7.6810000e+01  7.7400000e+00  1.0800000e+00\n",
      "    8.6000000e-01  2.1813000e+02  1.9213000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.2377000e+04\n",
      "    1.0000000e+00  7.8720000e+01 -3.0000000e-01  1.1800000e+00\n",
      "    2.7200000e+00  5.3360000e+01  1.9459000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.2403000e+04\n",
      "    2.0000000e+00  7.6170000e+01 -5.9700000e+00  8.9000000e-01\n",
      "    4.0200000e+00  1.8713000e+02  1.6279000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.2404000e+04\n",
      "    1.0000000e+00  7.8080000e+01  1.0000000e+00  1.2000000e-01\n",
      "    1.4300000e+00  1.7080000e+01  1.7709000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.3306000e+04\n",
      "    2.0000000e+00  7.5290000e+01 -2.6100000e+00  4.2000000e-01\n",
      "    2.9000000e-01  1.7646000e+02  7.5950000e+01]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.3478000e+04\n",
      "    2.0000000e+00  7.6370000e+01 -1.0990000e+01  1.7000000e-01\n",
      "    1.1000000e-01  2.0269000e+02  3.2716000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.4896000e+04\n",
      "    1.0000000e+00  7.9780000e+01 -8.1600000e+00  2.8800000e+00\n",
      "    1.9800000e+00  3.3250000e+01  7.4550000e+01]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.4904000e+04\n",
      "    2.0000000e+00  7.5390000e+01 -9.4700000e+00  2.3700000e+00\n",
      "    1.4100000e+00  3.5309000e+02  8.9940000e+01]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.4955000e+04\n",
      "    2.0000000e+00  7.6720000e+01  1.4500000e+00  8.8000000e-01\n",
      "    2.4500000e+00  1.4366000e+02  1.9873000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.4962000e+04\n",
      "    2.0000000e+00  6.0880000e+01 -5.2000000e-01  1.3400000e+00\n",
      "    1.2300000e+00  2.0968000e+02  5.8200000e+00]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.6163000e+04\n",
      "    1.0000000e+00  7.8600000e+01  4.0100000e+00  1.5000000e-01\n",
      "    1.2000000e+00  1.4720000e+01  2.1350000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  4.7996000e+04\n",
      "    2.0000000e+00  7.1990000e+01  4.3600000e+00  1.4400000e+00\n",
      "    1.6100000e+00  1.8821000e+02  1.1241000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  5.2421000e+04\n",
      "    1.0000000e+00  7.8930000e+01  5.3800000e+00  5.8000000e-01\n",
      "    1.4900000e+00  3.2605000e+02  1.2930000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  5.2459000e+04\n",
      "    2.0000000e+00  7.6670000e+01  1.0840000e+01  8.0000000e-01\n",
      "    3.7000000e-01  1.7973000e+02  1.0508000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  5.3441000e+04\n",
      "    2.0000000e+00  7.6380000e+01  4.6900000e+00  8.6000000e-01\n",
      "    3.8300000e+00  1.8802000e+02  2.1216000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  5.3504000e+04\n",
      "    2.0000000e+00  7.6330000e+01 -2.0000000e-02  1.2000000e-01\n",
      "    7.4000000e-01  3.1344000e+02  1.9248000e+02]\n",
      "  [ 2.0210909e+09  9.7000000e+01  7.0000000e+00  0.0000000e+00\n",
      "    3.0000000e+00  7.8930000e+01  2.7100000e+00  3.2000000e+00\n",
      "    7.8000000e+00  0.0000000e+00  0.0000000e+00]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_preprocess_train, x_preprocess_test, y_train, y_test = train_test_split(feature_arr, target_arr, test_size=0.3, random_state=5)\n",
    "#x_preprocess_test, x_preprocess_val, y_test, y_val = train_test_split(x_preprocess_test, y_test, test_size=0.5, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m np\u001b[39m.\u001b[39;49mseed(\u001b[39m23\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mshuffle([\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m]))\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39mshuffle([\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m]))\n",
      "File \u001b[0;32m~/virtualenvs/bdb_2023/lib/python3.8/site-packages/numpy/__init__.py:311\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m Tester\n\u001b[1;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 311\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmodule \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m has no attribute \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    312\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'seed'"
     ]
    }
   ],
   "source": [
    "np.seed(24)\n",
    "\n",
    "print(np.shuffle([2,3,4,5,6]))\n",
    "print(np.shuffle([2,3,4,5,6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.seed(24)\n",
    "np.random.shuffle(x_train)\n",
    "np.random.shuffle(y_train)\n",
    "\n",
    "# SHUFFLE Y's TOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nFeature list:\\n['gameId', 'playId', 'frameId', 'nflId', 'team_indicator', 'adj_x', 'adj_y', 's', 'a', 'adj_o', 'adj_dir']\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Feature list:\n",
    "['gameId', 'playId', 'frameId', 'nflId', 'team_indicator', 'adj_x', 'adj_y', 's', 'a', 'adj_o', 'adj_dir']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean/std of each feature. (N*23, 11) vector\n",
    "train_mu = np.mean(x_train.reshape(-1,x_train.shape[-1]),axis=0)\n",
    "train_std = np.std(x_train.reshape(-1,x_train.shape[-1]),axis=0)\n",
    "\n",
    "# don't standardize game, play, frame, nflid, or team_indicator features\n",
    "x_train[:,:,5:] = (x_train[:,:,5:] - train_mu[5:])/train_std[5:]\n",
    "x_val[:,:,5:] = (x_val[:,:,5:] - train_mu[5:])/train_std[5:]\n",
    "x_test[:,:,5:] = (x_test[:,:,5:] - train_mu[5:])/train_std[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 196648\n",
      "number of test examples = 42170\n",
      "X_train shape: (196648, 23, 11)\n",
      "Y_train shape: (196648, 2)\n",
      "X_val shape: (42131, 23, 11)\n",
      "Y_val shape: (42131, 2)\n",
      "X_test shape: (42170, 23, 11)\n",
      "Y_test shape: (42170, 2)\n"
     ]
    }
   ],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "print (\"number of training examples = \" + str(x_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(x_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(x_train.shape))\n",
    "print (\"Y_train shape: \" + str(y_train.shape))\n",
    "print (\"X_val shape: \" + str(x_val.shape))\n",
    "print (\"Y_val shape: \" + str(y_val.shape))\n",
    "print (\"X_test shape: \" + str(x_test.shape))\n",
    "print (\"Y_test shape: \" + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./cleaned_data/x_train\", x_train)\n",
    "np.save(\"./cleaned_data/y_train\", y_train)\n",
    "np.save(\"./cleaned_data/x_val\", x_val)\n",
    "np.save(\"./cleaned_data/y_val\", y_val)\n",
    "np.save(\"./cleaned_data/x_test\", x_test)\n",
    "np.save(\"./cleaned_data/y_test\", y_test)\n",
    "np.save(\"./cleaned_data/train_mu\", train_mu)\n",
    "np.save(\"./cleaned_data/train_std\", train_std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    return bce(y_true[:,0], y_pred[:,0]) + mse(y_true[:,1], y_pred[:,1])\n",
    "\n",
    "def bce_metric(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_true[:,0], y_pred[:,0], from_logits=True))\n",
    "    \n",
    "    #logit_max = K.clip(y_pred, 1e-12, 1e12)\n",
    "    #tf.print(y_pred[:,0])\n",
    "    #tf.print(logit_max[:,0])\n",
    "    #probs = 1/(1+K.exp(-logit_max[:,0]))\n",
    "    #return -K.mean( y_true[:,0]*K.log(probs) + (1-y_true[:,0])*K.log(1-probs))\n",
    "\n",
    "def mse_metric(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred[:,1] - y_true[:,1]), axis=-1)\n",
    "\n",
    "# https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,0] * y_pred[:,0], 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true[:,0], 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,0] * y_pred[:,0], 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred[:,0], 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "            tfl.Flatten(input_shape=(23, 7)),\n",
    "            tfl.Dense(100, activation='relu'),\n",
    "            tfl.Dense(80, activation='relu'), \n",
    "            tfl.Dense(2,activation=None)\n",
    "        ])\n",
    "model.compile(optimizer='adam',\n",
    "              loss=my_loss,\n",
    "              metrics=[bce_metric, mse_metric, recall, precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6146/6146 [==============================] - 13s 2ms/step - loss: 1.3716 - bce_metric: 0.2849 - mse_metric: 1.0865 - recall: 1.1390e-04 - precision: 3.1960e-05\n",
      "Epoch 2/5\n",
      "6146/6146 [==============================] - 12s 2ms/step - loss: 1.3586 - bce_metric: 0.2828 - mse_metric: 1.0760 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 3/5\n",
      "6146/6146 [==============================] - 12s 2ms/step - loss: 1.3571 - bce_metric: 0.2825 - mse_metric: 1.0745 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 4/5\n",
      "6146/6146 [==============================] - 12s 2ms/step - loss: 1.3553 - bce_metric: 0.2819 - mse_metric: 1.0733 - recall: 0.0000e+00 - precision: 0.0000e+00\n",
      "Epoch 5/5\n",
      "6146/6146 [==============================] - 16s 3ms/step - loss: 1.3527 - bce_metric: 0.2810 - mse_metric: 1.0716 - recall: 0.0000e+00 - precision: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "history = model.fit(x_train[:,:,4:], y_train, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317/1317 - 2s - loss: 2.0911 - bce_metric: 0.8982 - mse_metric: 1.1923 - recall: 0.0036 - precision: 0.0110 - 2s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_bce, val_mse, val_recall, val_precision = model.evaluate(x_val[:,:,4:], y_val, verbose=2)\n",
    "\n",
    "metrics_df = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>bce_metric</th>\n",
       "      <th>mse_metric</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.156930</td>\n",
       "      <td>0.231311</td>\n",
       "      <td>0.925618</td>\n",
       "      <td>0.085188</td>\n",
       "      <td>0.186666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.696731</td>\n",
       "      <td>0.137030</td>\n",
       "      <td>0.559678</td>\n",
       "      <td>0.418932</td>\n",
       "      <td>0.665055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.475289</td>\n",
       "      <td>0.090597</td>\n",
       "      <td>0.384704</td>\n",
       "      <td>0.606448</td>\n",
       "      <td>0.788535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.357305</td>\n",
       "      <td>0.064594</td>\n",
       "      <td>0.292707</td>\n",
       "      <td>0.713964</td>\n",
       "      <td>0.846681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.288632</td>\n",
       "      <td>0.049381</td>\n",
       "      <td>0.239251</td>\n",
       "      <td>0.765980</td>\n",
       "      <td>0.866968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.242342</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.204356</td>\n",
       "      <td>0.809271</td>\n",
       "      <td>0.886129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.201743</td>\n",
       "      <td>0.029613</td>\n",
       "      <td>0.172126</td>\n",
       "      <td>0.836978</td>\n",
       "      <td>0.896455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.182937</td>\n",
       "      <td>0.024706</td>\n",
       "      <td>0.158225</td>\n",
       "      <td>0.857228</td>\n",
       "      <td>0.903895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.158901</td>\n",
       "      <td>0.019616</td>\n",
       "      <td>0.139280</td>\n",
       "      <td>0.873908</td>\n",
       "      <td>0.908965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.142864</td>\n",
       "      <td>0.016687</td>\n",
       "      <td>0.126193</td>\n",
       "      <td>0.888765</td>\n",
       "      <td>0.918984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  bce_metric  mse_metric    recall  precision\n",
       "0  1.156930    0.231311    0.925618  0.085188   0.186666\n",
       "1  0.696731    0.137030    0.559678  0.418932   0.665055\n",
       "2  0.475289    0.090597    0.384704  0.606448   0.788535\n",
       "3  0.357305    0.064594    0.292707  0.713964   0.846681\n",
       "4  0.288632    0.049381    0.239251  0.765980   0.866968\n",
       "5  0.242342    0.038002    0.204356  0.809271   0.886129\n",
       "6  0.201743    0.029613    0.172126  0.836978   0.896455\n",
       "7  0.182937    0.024706    0.158225  0.857228   0.903895\n",
       "8  0.158901    0.019616    0.139280  0.873908   0.908965\n",
       "9  0.142864    0.016687    0.126193  0.888765   0.918984"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss = 0.20938993990421295\n",
      "val_bce = 0.02983475849032402\n",
      "val_mse = 0.17955544590950012\n",
      "val_recall = 0.8652931451797485\n",
      "val_precision = 0.8892954587936401\n"
     ]
    }
   ],
   "source": [
    "print(f\"val loss = {val_loss}\")\n",
    "print(f\"val_bce = {val_bce}\")\n",
    "print(f\"val_mse = {val_mse}\")\n",
    "print(f\"val_recall = {val_recall}\")\n",
    "print(f\"val_precision = {val_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_string = f\"models/basic_model/epochs{NUM_EPOCHS}.ckpt\"\n",
    "model.save_weights(model_string.format(epoch=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define baseline model\n",
    "# model = tf.keras.Sequential([\n",
    "#             tfl.Flatten(input_shape=(23, 7)),\n",
    "#             tfl.Dense(100, activation='relu'),\n",
    "#             tfl.Dense(80, activation='relu'), \n",
    "#             tfl.Dense(2,activation=None)\n",
    "#         ])\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='mean_squared_error',\n",
    "#               metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "# history = model.fit(x_train, y_train, epochs=3)\n",
    "# val_loss, val_mse = model.evaluate(x_val, y_val, verbose=2)\n",
    "# print('Val mse:', val_mse)\n",
    "# metrics_df = pd.DataFrame(history.history)\n",
    "# #metrics_df.loss.plot(title='Model loss',figsize=(6,3)).set(xlabel='Epoch',ylabel='Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bdb_2023')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64e913be5900ee3bfd48533456727a82d0e0b84d6c12de93770bb09b0509b267"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
