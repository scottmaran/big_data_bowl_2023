{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 09:24:05.538731: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import tensorflow.keras.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = np.load(\"./cleaned_data/small/x_train.npy\")\n",
    "y_train = np.load(\"./cleaned_data/small/y_train.npy\")\n",
    "train_mu = np.load(\"./cleaned_data/small/train_mu.npy\")\n",
    "train_std = np.load(\"./cleaned_data/small/train_std.npy\")\n",
    "x_val = np.load(\"./cleaned_data/small/x_val.npy\")\n",
    "y_val= np.load(\"./cleaned_data/small/y_val.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5991, 23, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = [no sack, sack, time to sack]\n",
    "# x = (M, 23, 11)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def my_loss(y_true, y_pred):\n",
    "    bce = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # get mse of only true positives\n",
    "    true_sack_mask = y_true[:1]==1\n",
    "    # checked, mse function can take in array of length zero\n",
    "    return bce(y_true[:,0:-1], y_pred[:,0:-1]) + mse(y_true[true_sack_mask], y_pred[true_sack_mask])\n",
    "\n",
    "def bce_metric(y_true, y_pred):\n",
    "    return K.mean(K.binary_crossentropy(y_true[:,0:-1], y_pred[:,0:-1], from_logits=False))\n",
    "\n",
    "def mse_metric(y_true, y_pred):\n",
    "    # get mse of only true positives\n",
    "    true_sack_mask = y_true[:1]==1\n",
    "    return K.mean(K.square(y_true[true_sack_mask] - y_pred[true_sack_mask]), axis=-1)\n",
    "    # return K.mean(K.square(y_pred[:,-1] - y_true[:,-1]), axis=-1)\n",
    "\n",
    "# https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1] * y_pred[:,1], 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true[:,1], 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1] * y_pred[:,1], 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred[:,1], 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nModel\\n\\nhow cropping layer works - https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-cropping-layers-with-keras.md\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Model\n",
    "\n",
    "how cropping layer works - https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-cropping-layers-with-keras.md\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Output:\n",
    "[prob of no sack, prob of sack, time till sack]\n",
    "\n",
    "If predict no sack, doesn't matter what time is (recorded as -1 in training data)\n",
    "'''\n",
    "\n",
    "def createModel(input_shape = (23,7)):\n",
    "    \n",
    "    X = tfl.Input(input_shape)  # define the input to the model\n",
    "    flat = tfl.Flatten(input_shape=(23, 7))(X)     # Flatten to pass into linear layers\n",
    "    d1 = tfl.Dense(50, activation='relu')(flat)\n",
    "    d3 = tfl.Dense(3,activation=None)(d1)\n",
    "    \n",
    "    # have layer (batch_size, 3). Want to take (b, [0,1]) and turn them into probabilities, and keep (b, [2]) as time\n",
    "    # https://datascience.stackexchange.com/questions/86740/how-to-slice-an-input-in-keras\n",
    "    intermediate = tfl.Reshape((3,1), input_shape=(3,))(d3)\n",
    "    \n",
    "    probs = tfl.Cropping1D(cropping=(0,1))(intermediate)\n",
    "    probs = tfl.Reshape((2,), input_shape=(2,1))(probs)\n",
    "    probs = tfl.Activation('softmax')(probs)\n",
    "    \n",
    "    time = tfl.Cropping1D(cropping=(2,0))(intermediate)\n",
    "    time = tfl.Reshape((1,), input_shape=(1,1))(time)\n",
    "    \n",
    "    # concatenate the probabilities and predicted_time_to_sack back into one layer\n",
    "    out = tfl.Concatenate(axis=-1)([probs, time])\n",
    "    \n",
    "    model = Model(inputs=X, outputs=out)        # create model\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 23, 7)]      0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 161)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           8100        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 3)            153         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 3, 1)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " cropping1d (Cropping1D)        (None, 2, 1)         0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 2)            0           ['cropping1d[0][0]']             \n",
      "                                                                                                  \n",
      " cropping1d_1 (Cropping1D)      (None, 1, 1)         0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 2)            0           ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1)            0           ['cropping1d_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3)            0           ['activation[0][0]',             \n",
      "                                                                  'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,253\n",
      "Trainable params: 8,253\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 09:24:12.159302: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = createModel()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPS = 1e-07\n",
    "\n",
    "opt = optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    epsilon=EPS)\n",
    "\n",
    "model.compile(loss = my_loss, optimizer = opt, metrics = [metrics.CategoricalAccuracy(), bce_metric, mse_metric, recall, precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better optimizer\n",
    "\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=LEARNING_RATE,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "scheduled_opt = optimizers.Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    epsilon=EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "188/188 [==============================] - 2s 3ms/step - loss: 0.3426 - categorical_accuracy: 0.6483 - bce_metric: 0.2739 - mse_metric: 0.0723 - recall: 0.0241 - precision: 0.0107\n",
      "Epoch 2/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2819 - categorical_accuracy: 0.7565 - bce_metric: 0.2246 - mse_metric: 0.0562 - recall: 0.0018 - precision: 0.0053   \n",
      "Epoch 3/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2585 - categorical_accuracy: 0.7727 - bce_metric: 0.2137 - mse_metric: 0.0441 - recall: 0.0031 - precision: 0.0106\n",
      "Epoch 4/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2713 - categorical_accuracy: 0.7413 - bce_metric: 0.2040 - mse_metric: 0.0663 - recall: 0.0177 - precision: 0.0266\n",
      "Epoch 5/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2390 - categorical_accuracy: 0.2527 - bce_metric: 0.2017 - mse_metric: 0.0378 - recall: 0.0135 - precision: 0.0266 \n",
      "Epoch 6/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2144 - categorical_accuracy: 0.2793 - bce_metric: 0.1887 - mse_metric: 0.0265 - recall: 0.0204 - precision: 0.0585 \n",
      "Epoch 7/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2179 - categorical_accuracy: 0.3225 - bce_metric: 0.1837 - mse_metric: 0.0337 - recall: 0.0493 - precision: 0.1011\n",
      "Epoch 8/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2175 - categorical_accuracy: 0.2694 - bce_metric: 0.1735 - mse_metric: 0.0436 - recall: 0.0858 - precision: 0.1489\n",
      "Epoch 9/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.2253 - categorical_accuracy: 0.2692 - bce_metric: 0.1630 - mse_metric: 0.0617 - recall: 0.1145 - precision: 0.1995\n",
      "Epoch 10/25\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.2105 - categorical_accuracy: 0.2644 - bce_metric: 0.1519 - mse_metric: 0.0589 - recall: 0.1376 - precision: 0.2606\n",
      "Epoch 11/25\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.1829 - categorical_accuracy: 0.2944 - bce_metric: 0.1459 - mse_metric: 0.0368 - recall: 0.1837 - precision: 0.2793\n",
      "Epoch 12/25\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.1794 - categorical_accuracy: 0.2786 - bce_metric: 0.1357 - mse_metric: 0.0432 - recall: 0.1730 - precision: 0.3165\n",
      "Epoch 13/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1413 - categorical_accuracy: 0.3003 - bce_metric: 0.1226 - mse_metric: 0.0184 - recall: 0.2657 - precision: 0.4255\n",
      "Epoch 14/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1457 - categorical_accuracy: 0.2714 - bce_metric: 0.1165 - mse_metric: 0.0292 - recall: 0.2928 - precision: 0.4849\n",
      "Epoch 15/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.1284 - categorical_accuracy: 0.2821 - bce_metric: 0.1118 - mse_metric: 0.0161 - recall: 0.3112 - precision: 0.4743\n",
      "Epoch 16/25\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.1597 - categorical_accuracy: 0.3297 - bce_metric: 0.1122 - mse_metric: 0.0480 - recall: 0.3238 - precision: 0.5111\n",
      "Epoch 17/25\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.2269 - categorical_accuracy: 0.6588 - bce_metric: 0.1037 - mse_metric: 0.1225 - recall: 0.3329 - precision: 0.4867\n",
      "Epoch 18/25\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.1299 - categorical_accuracy: 0.6413 - bce_metric: 0.0975 - mse_metric: 0.0320 - recall: 0.3451 - precision: 0.5186\n",
      "Epoch 19/25\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.1242 - categorical_accuracy: 0.5283 - bce_metric: 0.0924 - mse_metric: 0.0313 - recall: 0.4229 - precision: 0.5718\n",
      "Epoch 20/25\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.1121 - categorical_accuracy: 0.5792 - bce_metric: 0.0875 - mse_metric: 0.0245 - recall: 0.4209 - precision: 0.5824\n",
      "Epoch 21/25\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.1753 - categorical_accuracy: 0.5891 - bce_metric: 0.0778 - mse_metric: 0.0968 - recall: 0.5147 - precision: 0.6658\n",
      "Epoch 22/25\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.1302 - categorical_accuracy: 0.8381 - bce_metric: 0.0892 - mse_metric: 0.0407 - recall: 0.4323 - precision: 0.5807\n",
      "Epoch 23/25\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0906 - categorical_accuracy: 0.7605 - bce_metric: 0.0735 - mse_metric: 0.0169 - recall: 0.5096 - precision: 0.6436\n",
      "Epoch 24/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0687 - categorical_accuracy: 0.7775 - bce_metric: 0.0631 - mse_metric: 0.0054 - recall: 0.5651 - precision: 0.7030\n",
      "Epoch 25/25\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0895 - categorical_accuracy: 0.8715 - bce_metric: 0.0599 - mse_metric: 0.0295 - recall: 0.5746 - precision: 0.7181\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 25\n",
    "history = model.fit(x_train[:,:,4:], y_train, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of training plays with no sack = 0.941\n"
     ]
    }
   ],
   "source": [
    "train_no_sack = np.round(np.sum(y_train[:,0])/len(y_train), 3)\n",
    "print(f\"Percentage of training plays with no sack = {train_no_sack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 165ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9.9827349e-01,  1.7265019e-03, -3.5695143e+00],\n",
       "       [ 9.9107802e-01,  8.9220200e-03, -2.0458045e+00],\n",
       "       [ 8.4786421e-01,  1.5213583e-01, -1.6954126e+00],\n",
       "       [ 9.9284792e-01,  7.1520060e-03,  4.1887766e-01],\n",
       "       [ 9.6189880e-01,  3.8101166e-02,  1.3119957e+00]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:5,:,4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>bce_metric</th>\n",
       "      <th>mse_metric</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.175253</td>\n",
       "      <td>0.589050</td>\n",
       "      <td>0.077819</td>\n",
       "      <td>0.096791</td>\n",
       "      <td>0.514716</td>\n",
       "      <td>0.665780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.130203</td>\n",
       "      <td>0.838090</td>\n",
       "      <td>0.089156</td>\n",
       "      <td>0.040707</td>\n",
       "      <td>0.432320</td>\n",
       "      <td>0.580674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.090646</td>\n",
       "      <td>0.760474</td>\n",
       "      <td>0.073508</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>0.509574</td>\n",
       "      <td>0.643617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.068715</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.063071</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.565109</td>\n",
       "      <td>0.703014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.089518</td>\n",
       "      <td>0.871474</td>\n",
       "      <td>0.059918</td>\n",
       "      <td>0.029455</td>\n",
       "      <td>0.574633</td>\n",
       "      <td>0.718085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  categorical_accuracy  bce_metric  mse_metric    recall  \\\n",
       "20  0.175253              0.589050    0.077819    0.096791  0.514716   \n",
       "21  0.130203              0.838090    0.089156    0.040707  0.432320   \n",
       "22  0.090646              0.760474    0.073508    0.016895  0.509574   \n",
       "23  0.068715              0.777500    0.063071    0.005398  0.565109   \n",
       "24  0.089518              0.871474    0.059918    0.029455  0.574633   \n",
       "\n",
       "    precision  \n",
       "20   0.665780  \n",
       "21   0.580674  \n",
       "22   0.643617  \n",
       "23   0.703014  \n",
       "24   0.718085  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of validation plays with no sack = 0.947\n"
     ]
    }
   ],
   "source": [
    "num_no_sack = np.round(np.sum(y_val[:,0])/len(y_val), 3)\n",
    "print(f\"Percentage of validation plays with no sack = {num_no_sack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 - 1s - loss: 0.4084 - categorical_accuracy: 0.8512 - bce_metric: 0.3028 - mse_metric: 0.0969 - recall: 0.0244 - precision: 0.0244 - 520ms/epoch - 13ms/step\n"
     ]
    }
   ],
   "source": [
    "val_loss, cat_acc, val_bce, val_mse, val_recall, val_precision = model.evaluate(x_val[:,:,4:], y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss = 0.4084392189979553\n",
      "categorical accuracy = 0.8512461185455322\n",
      "val_bce = 0.302818238735199\n",
      "val_mse = 0.096922367811203\n",
      "val_recall = 0.024390241131186485\n",
      "val_precision = 0.024390241131186485\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"val loss = {val_loss}\")\n",
    "print(f\"categorical accuracy = {cat_acc}\")\n",
    "print(f\"val_bce = {val_bce}\")\n",
    "print(f\"val_mse = {val_mse}\")\n",
    "print(f\"val_recall = {val_recall}\")\n",
    "print(f\"val_precision = {val_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.98357046, 0.99988365, 0.9999479 , ..., 0.9999821 , 0.99990845,\n",
       "       0.9998735 ], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_val[:,:,4:])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kdnuggets.com/2021/02/saving-loading-models-tensorflow.html\n",
    "\n",
    "model_string = f\"models/third_model/weights_epochs{NUM_EPOCHS}\"\n",
    "model.save_weights(model_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bdb_2023')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64e913be5900ee3bfd48533456727a82d0e0b84d6c12de93770bb09b0509b267"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
