{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-07 13:39:38.025669: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import tensorflow.keras.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = np.load(\"./cleaned_data/small/x_train.npy\")\n",
    "y_train = np.load(\"./cleaned_data/small/y_train.npy\")\n",
    "train_mu = np.load(\"./cleaned_data/small/train_mu.npy\")\n",
    "train_std = np.load(\"./cleaned_data/small/train_std.npy\")\n",
    "x_val = np.load(\"./cleaned_data/small/x_val.npy\")\n",
    "y_val= np.load(\"./cleaned_data/small/y_val.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5991, 23, 11)\n",
      "(1284, 23, 11)\n"
     ]
    }
   ],
   "source": [
    "# y = [no sack, sack, time to sack]\n",
    "# x = (M, 23, 11)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def my_loss(y_true, y_output):\n",
    "    bce = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # get mse of only true positives\n",
    "    true_sack_mask = y_true[:,1]==1\n",
    "\n",
    "    if len(y_true[true_sack_mask]) == 0:\n",
    "        return bce(y_true[:,0:-1], y_output[:,0:-1])\n",
    "    else:\n",
    "        return bce(y_true[:,0:-1], y_output[:,0:-1]) + mse(y_true[true_sack_mask][:,-1], y_output[true_sack_mask][:,-1])\n",
    "\n",
    "def bce_metric(y_true, y_output):\n",
    "    return K.mean(K.binary_crossentropy(y_true[:,0:-1], y_output[:,0:-1], from_logits=False))\n",
    "\n",
    "def mse_metric(y_true, y_output):\n",
    "    # get mse of only true positives\n",
    "    true_sack_mask = y_true[:,1]==1\n",
    "    if len(y_true[true_sack_mask]) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return K.mean(K.square(y_true[true_sack_mask][:,-1] - y_output[true_sack_mask][:,-1]), axis=-1)\n",
    "    # return K.mean(K.square(y_pred[:,-1] - y_true[:,-1]), axis=-1)\n",
    "    \n",
    "def accuracy_metric(y_true, y_output):\n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    return K.mean(K.cast(y_true[:,1] == preds, 'float32'))\n",
    "\n",
    "# https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "def recall(y_true, y_output):\n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1] * preds, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true[:,1], 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_output):\n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1] * preds, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(preds, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nModel\\n\\nhow cropping layer works - https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-cropping-layers-with-keras.md\\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Model\n",
    "\n",
    "how cropping layer works - https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-cropping-layers-with-keras.md\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Output:\n",
    "[prob of no sack, prob of sack, time till sack]\n",
    "\n",
    "If predict no sack, doesn't matter what time is (recorded as -1 in training data)\n",
    "'''\n",
    "\n",
    "def createModel(input_shape = (23,7)):\n",
    "    \n",
    "    X = tfl.Input(input_shape)  # define the input to the model\n",
    "    flat = tfl.Flatten(input_shape=(23, 7))(X)     # Flatten to pass into linear layers\n",
    "    d1 = tfl.Dense(50, activation='relu')(flat)\n",
    "    d3 = tfl.Dense(3,activation=None)(d1)\n",
    "    \n",
    "    # have layer (batch_size, 3). Want to take (b, [0,1]) and turn them into probabilities, and keep (b, [2]) as time\n",
    "    # https://datascience.stackexchange.com/questions/86740/how-to-slice-an-input-in-keras\n",
    "    intermediate = tfl.Reshape((3,1), input_shape=(3,))(d3)\n",
    "    \n",
    "    probs = tfl.Cropping1D(cropping=(0,1))(intermediate)\n",
    "    probs = tfl.Reshape((2,), input_shape=(2,1))(probs)\n",
    "    probs = tfl.Activation('softmax')(probs)\n",
    "    \n",
    "    time = tfl.Cropping1D(cropping=(2,0))(intermediate)\n",
    "    time = tfl.Reshape((1,), input_shape=(1,1))(time)\n",
    "    \n",
    "    # concatenate the probabilities and predicted_time_to_sack back into one layer\n",
    "    out = tfl.Concatenate(axis=-1)([probs, time])\n",
    "    \n",
    "    model = Model(inputs=X, outputs=out)        # create model\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 23, 7)]      0           []                               \n",
      "                                                                                                  \n",
      " flatten_10 (Flatten)           (None, 161)          0           ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " dense_20 (Dense)               (None, 50)           8100        ['flatten_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense_21 (Dense)               (None, 3)            153         ['dense_20[0][0]']               \n",
      "                                                                                                  \n",
      " reshape_30 (Reshape)           (None, 3, 1)         0           ['dense_21[0][0]']               \n",
      "                                                                                                  \n",
      " cropping1d_20 (Cropping1D)     (None, 2, 1)         0           ['reshape_30[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_31 (Reshape)           (None, 2)            0           ['cropping1d_20[0][0]']          \n",
      "                                                                                                  \n",
      " cropping1d_21 (Cropping1D)     (None, 1, 1)         0           ['reshape_30[0][0]']             \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 2)            0           ['reshape_31[0][0]']             \n",
      "                                                                                                  \n",
      " reshape_32 (Reshape)           (None, 1)            0           ['cropping1d_21[0][0]']          \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 3)            0           ['activation_10[0][0]',          \n",
      "                                                                  'reshape_32[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,253\n",
      "Trainable params: 8,253\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = createModel()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.000001\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPS = 1e-07\n",
    "\n",
    "# Better optimizer\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=LEARNING_RATE,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "scheduled_opt = optimizers.Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    epsilon=EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    epsilon=EPS)\n",
    "\n",
    "model.compile(loss = my_loss, optimizer = scheduled_opt, metrics = [accuracy_metric, bce_metric, mse_metric, recall, precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "188/188 [==============================] - 4s 7ms/step - loss: 5.7822 - accuracy_metric: 0.9303 - bce_metric: 0.2879 - mse_metric: 5.5163 - recall: 0.0186 - precision: 0.0293 - val_loss: 4.3895 - val_accuracy_metric: 0.9352 - val_bce_metric: 0.2569 - val_mse_metric: 4.0435 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 2/20\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 5.9504 - accuracy_metric: 0.9316 - bce_metric: 0.2874 - mse_metric: 5.6394 - recall: 0.0168 - precision: 0.0319 - val_loss: 4.3453 - val_accuracy_metric: 0.9360 - val_bce_metric: 0.2562 - val_mse_metric: 4.0009 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 3/20\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.1383 - accuracy_metric: 0.9312 - bce_metric: 0.2903 - mse_metric: 4.8436 - recall: 0.0164 - precision: 0.0266 - val_loss: 4.3045 - val_accuracy_metric: 0.9360 - val_bce_metric: 0.2556 - val_mse_metric: 3.9616 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 4/20\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.3905 - accuracy_metric: 0.9327 - bce_metric: 0.2855 - mse_metric: 5.0828 - recall: 0.0155 - precision: 0.0257 - val_loss: 4.2612 - val_accuracy_metric: 0.9367 - val_bce_metric: 0.2550 - val_mse_metric: 3.9198 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 5/20\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 5.5440 - accuracy_metric: 0.9327 - bce_metric: 0.2853 - mse_metric: 5.2361 - recall: 0.0155 - precision: 0.0319 - val_loss: 4.2181 - val_accuracy_metric: 0.9367 - val_bce_metric: 0.2544 - val_mse_metric: 3.8782 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 6/20\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.4264 - accuracy_metric: 0.9317 - bce_metric: 0.2890 - mse_metric: 5.1261 - recall: 0.0186 - precision: 0.0239 - val_loss: 4.1767 - val_accuracy_metric: 0.9367 - val_bce_metric: 0.2538 - val_mse_metric: 3.8382 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 7/20\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.4345 - accuracy_metric: 0.9328 - bce_metric: 0.2844 - mse_metric: 5.1279 - recall: 0.0188 - precision: 0.0319 - val_loss: 4.1364 - val_accuracy_metric: 0.9375 - val_bce_metric: 0.2532 - val_mse_metric: 3.7993 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 8/20\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.2596 - accuracy_metric: 0.9330 - bce_metric: 0.2840 - mse_metric: 4.9542 - recall: 0.0137 - precision: 0.0239 - val_loss: 4.0981 - val_accuracy_metric: 0.9383 - val_bce_metric: 0.2526 - val_mse_metric: 3.7623 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 9/20\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.3766 - accuracy_metric: 0.9332 - bce_metric: 0.2837 - mse_metric: 5.0710 - recall: 0.0124 - precision: 0.0266 - val_loss: 4.0576 - val_accuracy_metric: 0.9383 - val_bce_metric: 0.2521 - val_mse_metric: 3.7233 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 10/20\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.1620 - accuracy_metric: 0.9333 - bce_metric: 0.2833 - mse_metric: 4.8577 - recall: 0.0110 - precision: 0.0257 - val_loss: 4.0196 - val_accuracy_metric: 0.9383 - val_bce_metric: 0.2515 - val_mse_metric: 3.6865 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 11/20\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.1213 - accuracy_metric: 0.9337 - bce_metric: 0.2831 - mse_metric: 4.8175 - recall: 0.0088 - precision: 0.0257 - val_loss: 3.9836 - val_accuracy_metric: 0.9390 - val_bce_metric: 0.2510 - val_mse_metric: 3.6518 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 12/20\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.9616 - accuracy_metric: 0.9332 - bce_metric: 0.2839 - mse_metric: 4.6741 - recall: 0.0121 - precision: 0.0293 - val_loss: 3.9486 - val_accuracy_metric: 0.9390 - val_bce_metric: 0.2505 - val_mse_metric: 3.6181 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 13/20\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 4.9466 - accuracy_metric: 0.9340 - bce_metric: 0.2823 - mse_metric: 4.6442 - recall: 0.0113 - precision: 0.0266 - val_loss: 3.9148 - val_accuracy_metric: 0.9398 - val_bce_metric: 0.2500 - val_mse_metric: 3.5854 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 14/20\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 4.7918 - accuracy_metric: 0.9340 - bce_metric: 0.2819 - mse_metric: 4.4904 - recall: 0.0108 - precision: 0.0266 - val_loss: 3.8802 - val_accuracy_metric: 0.9398 - val_bce_metric: 0.2495 - val_mse_metric: 3.5520 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 15/20\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 5.3180 - accuracy_metric: 0.9342 - bce_metric: 0.2821 - mse_metric: 5.0147 - recall: 0.0090 - precision: 0.0239 - val_loss: 3.8434 - val_accuracy_metric: 0.9398 - val_bce_metric: 0.2490 - val_mse_metric: 3.5165 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 16/20\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 5.0568 - accuracy_metric: 0.9330 - bce_metric: 0.2851 - mse_metric: 4.7823 - recall: 0.0099 - precision: 0.0239 - val_loss: 3.8102 - val_accuracy_metric: 0.9398 - val_bce_metric: 0.2485 - val_mse_metric: 3.4844 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 17/20\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 4.7107 - accuracy_metric: 0.9339 - bce_metric: 0.2815 - mse_metric: 4.4106 - recall: 0.0120 - precision: 0.0266 - val_loss: 3.7784 - val_accuracy_metric: 0.9398 - val_bce_metric: 0.2481 - val_mse_metric: 3.4537 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 18/20\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 4.8649 - accuracy_metric: 0.9345 - bce_metric: 0.2806 - mse_metric: 4.5644 - recall: 0.0151 - precision: 0.0266 - val_loss: 3.7467 - val_accuracy_metric: 0.9405 - val_bce_metric: 0.2476 - val_mse_metric: 3.4231 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 19/20\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.2194 - accuracy_metric: 0.9339 - bce_metric: 0.2815 - mse_metric: 4.9202 - recall: 0.0121 - precision: 0.0239 - val_loss: 3.7136 - val_accuracy_metric: 0.9405 - val_bce_metric: 0.2472 - val_mse_metric: 3.3911 - val_recall: 0.0122 - val_precision: 0.0244\n",
      "Epoch 20/20\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 5.2000 - accuracy_metric: 0.9345 - bce_metric: 0.2800 - mse_metric: 4.8987 - recall: 0.0186 - precision: 0.0239 - val_loss: 3.6814 - val_accuracy_metric: 0.9405 - val_bce_metric: 0.2468 - val_mse_metric: 3.3600 - val_recall: 0.0122 - val_precision: 0.0244\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "history = model.fit(x_train[:,:,4:], y_train, epochs=NUM_EPOCHS, validation_data=(x_val[:,:,4:], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of training plays with no sack = 0.941\n"
     ]
    }
   ],
   "source": [
    "train_no_sack = np.round(np.sum(y_train[:,0])/len(y_train), 3)\n",
    "print(f\"Percentage of training plays with no sack = {train_no_sack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.30376208,  0.69623786,  1.5447886 ],\n",
       "       [ 0.8638921 ,  0.13610792,  1.7055527 ],\n",
       "       [ 0.35448074,  0.64551926, -0.32487267],\n",
       "       [ 0.6310289 ,  0.36897105,  0.13501425],\n",
       "       [ 0.8446053 ,  0.15539473, -0.7607045 ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:5,:,4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy_metric</th>\n",
       "      <th>bce_metric</th>\n",
       "      <th>mse_metric</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy_metric</th>\n",
       "      <th>val_bce_metric</th>\n",
       "      <th>val_mse_metric</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.631446</td>\n",
       "      <td>0.713740</td>\n",
       "      <td>0.555776</td>\n",
       "      <td>6.050030</td>\n",
       "      <td>0.232890</td>\n",
       "      <td>0.060413</td>\n",
       "      <td>4.734457</td>\n",
       "      <td>0.721799</td>\n",
       "      <td>0.537242</td>\n",
       "      <td>4.102384</td>\n",
       "      <td>0.332114</td>\n",
       "      <td>0.069640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.178530</td>\n",
       "      <td>0.716803</td>\n",
       "      <td>0.553032</td>\n",
       "      <td>6.598741</td>\n",
       "      <td>0.202216</td>\n",
       "      <td>0.061228</td>\n",
       "      <td>4.674902</td>\n",
       "      <td>0.723323</td>\n",
       "      <td>0.533346</td>\n",
       "      <td>4.047948</td>\n",
       "      <td>0.332114</td>\n",
       "      <td>0.069640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.722048</td>\n",
       "      <td>0.720222</td>\n",
       "      <td>0.547747</td>\n",
       "      <td>6.173240</td>\n",
       "      <td>0.221543</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>4.620469</td>\n",
       "      <td>0.724848</td>\n",
       "      <td>0.529365</td>\n",
       "      <td>3.998605</td>\n",
       "      <td>0.319919</td>\n",
       "      <td>0.066232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.708419</td>\n",
       "      <td>0.724639</td>\n",
       "      <td>0.543701</td>\n",
       "      <td>6.138453</td>\n",
       "      <td>0.218883</td>\n",
       "      <td>0.058618</td>\n",
       "      <td>4.565050</td>\n",
       "      <td>0.728659</td>\n",
       "      <td>0.525514</td>\n",
       "      <td>3.948172</td>\n",
       "      <td>0.319919</td>\n",
       "      <td>0.068914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.872385</td>\n",
       "      <td>0.727109</td>\n",
       "      <td>0.541165</td>\n",
       "      <td>5.309736</td>\n",
       "      <td>0.243262</td>\n",
       "      <td>0.064430</td>\n",
       "      <td>4.514002</td>\n",
       "      <td>0.733994</td>\n",
       "      <td>0.521677</td>\n",
       "      <td>3.901999</td>\n",
       "      <td>0.319919</td>\n",
       "      <td>0.069912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy_metric  bce_metric  mse_metric    recall  precision  \\\n",
       "15  6.631446         0.713740    0.555776    6.050030  0.232890   0.060413   \n",
       "16  7.178530         0.716803    0.553032    6.598741  0.202216   0.061228   \n",
       "17  6.722048         0.720222    0.547747    6.173240  0.221543   0.059844   \n",
       "18  6.708419         0.724639    0.543701    6.138453  0.218883   0.058618   \n",
       "19  5.872385         0.727109    0.541165    5.309736  0.243262   0.064430   \n",
       "\n",
       "    val_loss  val_accuracy_metric  val_bce_metric  val_mse_metric  val_recall  \\\n",
       "15  4.734457             0.721799        0.537242        4.102384    0.332114   \n",
       "16  4.674902             0.723323        0.533346        4.047948    0.332114   \n",
       "17  4.620469             0.724848        0.529365        3.998605    0.319919   \n",
       "18  4.565050             0.728659        0.525514        3.948172    0.319919   \n",
       "19  4.514002             0.733994        0.521677        3.901999    0.319919   \n",
       "\n",
       "    val_precision  \n",
       "15       0.069640  \n",
       "16       0.069640  \n",
       "17       0.066232  \n",
       "18       0.068914  \n",
       "19       0.069912  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of validation plays with no sack = 0.947\n"
     ]
    }
   ],
   "source": [
    "num_no_sack = np.round(np.sum(y_val[:,0])/len(y_val), 3)\n",
    "print(f\"Percentage of validation plays with no sack = {num_no_sack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 - 0s - loss: 4.5140 - accuracy_metric: 0.7340 - bce_metric: 0.5217 - mse_metric: 3.9020 - recall: 0.3199 - precision: 0.0699 - 135ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "val_loss, cat_acc, val_bce, val_mse, val_recall, val_precision = model.evaluate(x_val[:,:,4:], y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss = 4.514001846313477\n",
      "categorical accuracy = 0.7339938879013062\n",
      "val_bce = 0.5216765999794006\n",
      "val_mse = 3.9019994735717773\n",
      "val_recall = 0.319918692111969\n",
      "val_precision = 0.0699116513133049\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"val loss = {val_loss}\")\n",
    "print(f\"categorical accuracy = {cat_acc}\")\n",
    "print(f\"val_bce = {val_bce}\")\n",
    "print(f\"val_mse = {val_mse}\")\n",
    "print(f\"val_recall = {val_recall}\")\n",
    "print(f\"val_precision = {val_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.4653594 , 0.8970736 , 0.6486465 , ..., 0.89433753, 0.8607381 ,\n",
       "       0.9926577 ], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_val[:,:,4:])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kdnuggets.com/2021/02/saving-loading-models-tensorflow.html\n",
    "\n",
    "model_string = f\"models/fifth_model/weights_epochs{NUM_EPOCHS}\"\n",
    "model.save_weights(model_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bdb_2023')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64e913be5900ee3bfd48533456727a82d0e0b84d6c12de93770bb09b0509b267"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
