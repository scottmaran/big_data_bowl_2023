{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 14:18:46.862052: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import tensorflow.keras.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = np.load(\"./cleaned_data/small/x_train.npy\")\n",
    "y_train = np.load(\"./cleaned_data/small/y_train.npy\")\n",
    "train_mu = np.load(\"./cleaned_data/small/train_mu.npy\")\n",
    "train_std = np.load(\"./cleaned_data/small/train_std.npy\")\n",
    "x_val = np.load(\"./cleaned_data/small/x_val.npy\")\n",
    "y_val= np.load(\"./cleaned_data/small/y_val.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5991, 23, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = [no sack, sack, time to sack]\n",
    "# x = (M, 23, 11)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def my_loss(y_true, y_output):\n",
    "    bce = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # get mse of only true positives\n",
    "    true_sack_mask = y_true[:,1]==1\n",
    "\n",
    "    if len(y_true[true_sack_mask]) == 0:\n",
    "        return bce(y_true[:,0:-1], y_output[:,0:-1])\n",
    "    else:\n",
    "        return bce(y_true[:,0:-1], y_output[:,0:-1]) + mse(y_true[true_sack_mask][:,-1], y_output[true_sack_mask][:,-1])\n",
    "\n",
    "def bce_metric(y_true, y_output):\n",
    "    return K.mean(K.binary_crossentropy(y_true[:,0:-1], y_output[:,0:-1], from_logits=False))\n",
    "\n",
    "def mse_metric(y_true, y_output):\n",
    "    # get mse of only true positives\n",
    "    true_sack_mask = y_true[:,1]==1\n",
    "    if len(y_true[true_sack_mask]) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return K.mean(K.square(y_true[true_sack_mask][:,-1] - y_output[true_sack_mask][:,-1]), axis=-1)\n",
    "    # return K.mean(K.square(y_pred[:,-1] - y_true[:,-1]), axis=-1)\n",
    "    \n",
    "def accuracy_metric(y_true, y_output):\n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    return K.mean(K.cast(y_true[:,1] == preds, 'float32'))\n",
    "\n",
    "# https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "def recall(y_true, y_output):\n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1] * preds, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true[:,1], 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_output):\n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1] * preds, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(preds, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nModel\\n\\nhow cropping layer works - https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-cropping-layers-with-keras.md\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Model\n",
    "\n",
    "how cropping layer works - https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-cropping-layers-with-keras.md\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Output:\n",
    "[prob of no sack, prob of sack, time till sack]\n",
    "\n",
    "If predict no sack, doesn't matter what time is (recorded as -1 in training data)\n",
    "'''\n",
    "\n",
    "def createModel(input_shape = (23,7)):\n",
    "    \n",
    "    X = tfl.Input(input_shape)  # define the input to the model\n",
    "    flat = tfl.Flatten(input_shape=(23, 7))(X)     # Flatten to pass into linear layers\n",
    "    d1 = tfl.Dense(50, activation='relu')(flat)\n",
    "    d3 = tfl.Dense(3,activation=None)(d1)\n",
    "    \n",
    "    # have layer (batch_size, 3). Want to take (b, [0,1]) and turn them into probabilities, and keep (b, [2]) as time\n",
    "    # https://datascience.stackexchange.com/questions/86740/how-to-slice-an-input-in-keras\n",
    "    intermediate = tfl.Reshape((3,1), input_shape=(3,))(d3)\n",
    "    \n",
    "    probs = tfl.Cropping1D(cropping=(0,1))(intermediate)\n",
    "    probs = tfl.Reshape((2,), input_shape=(2,1))(probs)\n",
    "    probs = tfl.Activation('softmax')(probs)\n",
    "    \n",
    "    time = tfl.Cropping1D(cropping=(2,0))(intermediate)\n",
    "    time = tfl.Reshape((1,), input_shape=(1,1))(time)\n",
    "    \n",
    "    # concatenate the probabilities and predicted_time_to_sack back into one layer\n",
    "    out = tfl.Concatenate(axis=-1)([probs, time])\n",
    "    \n",
    "    model = Model(inputs=X, outputs=out)        # create model\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 23, 7)]      0           []                               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 161)          0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50)           8100        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 3)            153         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 3, 1)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " cropping1d (Cropping1D)        (None, 2, 1)         0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_1 (Reshape)            (None, 2)            0           ['cropping1d[0][0]']             \n",
      "                                                                                                  \n",
      " cropping1d_1 (Cropping1D)      (None, 1, 1)         0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 2)            0           ['reshape_1[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_2 (Reshape)            (None, 1)            0           ['cropping1d_1[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 3)            0           ['activation[0][0]',             \n",
      "                                                                  'reshape_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,253\n",
      "Trainable params: 8,253\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-06 14:18:53.491465: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = createModel()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPS = 1e-07\n",
    "\n",
    "opt = optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    epsilon=EPS)\n",
    "\n",
    "model.compile(loss = my_loss, optimizer = opt, metrics = [accuracy_metric, bce_metric, mse_metric, recall, precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Better optimizer\n",
    "\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=LEARNING_RATE,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "scheduled_opt = optimizers.Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    epsilon=EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0442 - accuracy_metric: 1.0000 - bce_metric: 0.0070 - mse_metric: 0.0370 - recall: 0.8989 - precision: 0.8989\n",
      "Epoch 2/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy_metric: 0.9995 - bce_metric: 0.0079 - mse_metric: 0.0621 - recall: 0.8706 - precision: 0.8777\n",
      "Epoch 3/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0796 - accuracy_metric: 0.9983 - bce_metric: 0.0111 - mse_metric: 0.0682 - recall: 0.8243 - precision: 0.8316\n",
      "Epoch 4/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy_metric: 0.9987 - bce_metric: 0.0105 - mse_metric: 0.0657 - recall: 0.8426 - precision: 0.8484\n",
      "Epoch 5/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy_metric: 0.9982 - bce_metric: 0.0093 - mse_metric: 0.0565 - recall: 0.7926 - precision: 0.8070\n",
      "Epoch 6/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy_metric: 0.9995 - bce_metric: 0.0066 - mse_metric: 0.0502 - recall: 0.8825 - precision: 0.8883\n",
      "Epoch 7/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy_metric: 0.9997 - bce_metric: 0.0059 - mse_metric: 0.0440 - recall: 0.8422 - precision: 0.8457\n",
      "Epoch 8/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy_metric: 1.0000 - bce_metric: 0.0048 - mse_metric: 0.0259 - recall: 0.8511 - precision: 0.8511\n",
      "Epoch 9/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy_metric: 1.0000 - bce_metric: 0.0042 - mse_metric: 0.0201 - recall: 0.8245 - precision: 0.8245\n",
      "Epoch 10/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy_metric: 1.0000 - bce_metric: 0.0034 - mse_metric: 0.0139 - recall: 0.8457 - precision: 0.8457\n",
      "Epoch 11/30\n",
      "188/188 [==============================] - 1s 5ms/step - loss: 0.0192 - accuracy_metric: 1.0000 - bce_metric: 0.0032 - mse_metric: 0.0159 - recall: 0.8564 - precision: 0.8564\n",
      "Epoch 12/30\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0203 - accuracy_metric: 1.0000 - bce_metric: 0.0032 - mse_metric: 0.0171 - recall: 0.8404 - precision: 0.8404\n",
      "Epoch 13/30\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy_metric: 1.0000 - bce_metric: 0.0030 - mse_metric: 0.0148 - recall: 0.8564 - precision: 0.8564\n",
      "Epoch 14/30\n",
      "188/188 [==============================] - 1s 4ms/step - loss: 0.0257 - accuracy_metric: 1.0000 - bce_metric: 0.0032 - mse_metric: 0.0224 - recall: 0.8670 - precision: 0.8670\n",
      "Epoch 15/30\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy_metric: 0.9992 - bce_metric: 0.0045 - mse_metric: 0.0291 - recall: 0.8457 - precision: 0.8475\n",
      "Epoch 16/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy_metric: 0.9958 - bce_metric: 0.0128 - mse_metric: 0.0325 - recall: 0.7955 - precision: 0.8032\n",
      "Epoch 17/30\n",
      "188/188 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy_metric: 0.9993 - bce_metric: 0.0072 - mse_metric: 0.0371 - recall: 0.8254 - precision: 0.8270\n",
      "Epoch 18/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0621 - accuracy_metric: 0.9987 - bce_metric: 0.0071 - mse_metric: 0.0547 - recall: 0.8138 - precision: 0.8218\n",
      "Epoch 19/30\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy_metric: 0.9993 - bce_metric: 0.0055 - mse_metric: 0.0731 - recall: 0.8633 - precision: 0.8630\n",
      "Epoch 20/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy_metric: 0.9998 - bce_metric: 0.0042 - mse_metric: 0.0486 - recall: 0.8125 - precision: 0.8138\n",
      "Epoch 21/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy_metric: 0.9998 - bce_metric: 0.0032 - mse_metric: 0.0246 - recall: 0.8324 - precision: 0.8351\n",
      "Epoch 22/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy_metric: 1.0000 - bce_metric: 0.0023 - mse_metric: 0.0234 - recall: 0.8564 - precision: 0.8564\n",
      "Epoch 23/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0225 - accuracy_metric: 1.0000 - bce_metric: 0.0021 - mse_metric: 0.0203 - recall: 0.8723 - precision: 0.8723\n",
      "Epoch 24/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy_metric: 1.0000 - bce_metric: 0.0020 - mse_metric: 0.0264 - recall: 0.8723 - precision: 0.8723\n",
      "Epoch 25/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy_metric: 0.9997 - bce_metric: 0.0025 - mse_metric: 0.0239 - recall: 0.8324 - precision: 0.8351\n",
      "Epoch 26/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy_metric: 1.0000 - bce_metric: 0.0020 - mse_metric: 0.0263 - recall: 0.8511 - precision: 0.8511\n",
      "Epoch 27/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy_metric: 1.0000 - bce_metric: 0.0020 - mse_metric: 0.0321 - recall: 0.8564 - precision: 0.8564\n",
      "Epoch 28/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy_metric: 1.0000 - bce_metric: 0.0020 - mse_metric: 0.0385 - recall: 0.8617 - precision: 0.8617\n",
      "Epoch 29/30\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy_metric: 0.9997 - bce_metric: 0.0030 - mse_metric: 0.0339 - recall: 0.8710 - precision: 0.8723\n",
      "Epoch 30/30\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.0343 - accuracy_metric: 0.9998 - bce_metric: 0.0031 - mse_metric: 0.0310 - recall: 0.8723 - precision: 0.8710\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 30\n",
    "history = model.fit(x_train[:,:,4:], y_train, epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of training plays with no sack = 0.941\n"
     ]
    }
   ],
   "source": [
    "train_no_sack = np.round(np.sum(y_train[:,0])/len(y_train), 3)\n",
    "print(f\"Percentage of training plays with no sack = {train_no_sack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.9999690e-01, 3.0919468e-06, 2.4979432e+00],\n",
       "       [9.9997938e-01, 2.0623305e-05, 2.5297964e+00],\n",
       "       [9.9890745e-01, 1.0925011e-03, 1.2628291e+00],\n",
       "       [9.9559397e-01, 4.4059805e-03, 4.5964584e+00],\n",
       "       [9.9681205e-01, 3.1879521e-03, 2.5961945e+00]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:5,:,4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy_metric</th>\n",
       "      <th>bce_metric</th>\n",
       "      <th>mse_metric</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.028437</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.026323</td>\n",
       "      <td>0.851064</td>\n",
       "      <td>0.851064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.034247</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>0.032120</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.856383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.040685</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.038516</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.036739</td>\n",
       "      <td>0.999668</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.033873</td>\n",
       "      <td>0.871011</td>\n",
       "      <td>0.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.034295</td>\n",
       "      <td>0.999834</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.031027</td>\n",
       "      <td>0.872340</td>\n",
       "      <td>0.871011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy_metric  bce_metric  mse_metric    recall  precision\n",
       "25  0.028437         1.000000    0.002019    0.026323  0.851064   0.851064\n",
       "26  0.034247         1.000000    0.001990    0.032120  0.856383   0.856383\n",
       "27  0.040685         1.000000    0.002005    0.038516  0.861702   0.861702\n",
       "28  0.036739         0.999668    0.002972    0.033873  0.871011   0.872340\n",
       "29  0.034295         0.999834    0.003132    0.031027  0.872340   0.871011"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of validation plays with no sack = 0.947\n"
     ]
    }
   ],
   "source": [
    "num_no_sack = np.round(np.sum(y_val[:,0])/len(y_val), 3)\n",
    "print(f\"Percentage of validation plays with no sack = {num_no_sack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 - 0s - loss: 2.8002 - accuracy_metric: 0.9146 - bce_metric: 0.7119 - mse_metric: 2.0123 - recall: 0.0618 - precision: 0.0569 - 101ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "val_loss, cat_acc, val_bce, val_mse, val_recall, val_precision = model.evaluate(x_val[:,:,4:], y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss = 2.8001644611358643\n",
      "categorical accuracy = 0.9146341681480408\n",
      "val_bce = 0.7118798494338989\n",
      "val_mse = 2.012299060821533\n",
      "val_recall = 0.06178861856460571\n",
      "val_precision = 0.056910574436187744\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"val loss = {val_loss}\")\n",
    "print(f\"categorical accuracy = {cat_acc}\")\n",
    "print(f\"val_bce = {val_bce}\")\n",
    "print(f\"val_mse = {val_mse}\")\n",
    "print(f\"val_recall = {val_recall}\")\n",
    "print(f\"val_precision = {val_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8872072 , 0.9867906 , 0.8555738 , ..., 0.99581367, 0.9926259 ,\n",
       "       0.99644214], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_val[:,:,4:])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kdnuggets.com/2021/02/saving-loading-models-tensorflow.html\n",
    "\n",
    "model_string = f\"models/third_model/weights_epochs{NUM_EPOCHS}\"\n",
    "model.save_weights(model_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('bdb_2023')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64e913be5900ee3bfd48533456727a82d0e0b84d6c12de93770bb09b0509b267"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
