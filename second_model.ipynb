{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-09 08:27:42.978324: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import tensorflow.keras.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = np.load(\"./cleaned_data/x_train.npy\")\n",
    "y_train = np.load(\"./cleaned_data/y_train.npy\")\n",
    "train_mu = np.load(\"./cleaned_data/train_mu.npy\")\n",
    "train_std = np.load(\"./cleaned_data/train_std.npy\")\n",
    "x_val = np.load(\"./cleaned_data/x_val.npy\")\n",
    "y_val= np.load(\"./cleaned_data/y_val.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196648, 23, 11)\n",
      "(42131, 23, 11)\n"
     ]
    }
   ],
   "source": [
    "# y = [no sack, sack, time to sack]\n",
    "# x = (M, 23, 11)\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def my_loss(y_true, y_output):\n",
    "    bce = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    \n",
    "    # get mse of only true positives\n",
    "    true_sack_mask = y_true[:,1]==1\n",
    "\n",
    "    if len(y_true[true_sack_mask]) == 0:\n",
    "        return bce(y_true[:,0:-1], y_output[:,0:-1])\n",
    "    else:\n",
    "        return bce(y_true[:,0:-1], y_output[:,0:-1]) + mse(y_true[true_sack_mask][:,-1], y_output[true_sack_mask][:,-1])\n",
    "\n",
    "def bce_metric(y_true, y_output):\n",
    "    return K.mean(K.binary_crossentropy(y_true[:,0:-1], y_output[:,0:-1], from_logits=False))\n",
    "\n",
    "def mse_metric(y_true, y_output):\n",
    "    # get mse of only true positives\n",
    "    true_sack_mask = y_true[:,1]==1\n",
    "    if len(y_true[true_sack_mask]) == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return K.mean(K.square(y_true[true_sack_mask][:,-1] - y_output[true_sack_mask][:,-1]), axis=-1)\n",
    "    # return K.mean(K.square(y_pred[:,-1] - y_true[:,-1]), axis=-1)\n",
    "    \n",
    "def accuracy_metric(y_true, y_output):\n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    return K.mean(K.cast(y_true[:,1] == preds, 'float32'))\n",
    "\n",
    "# https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "def recall(y_true, y_output):\n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1] * preds, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true[:,1], 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision(y_true, y_output):\n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1] * preds, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(preds, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_loss(y_true, y_output):\n",
    "    \n",
    "    ground_positives = K.sum(y_true[:,1], axis=0) + K.epsilon()       # = TP + FN\n",
    "    pred_positives = K.sum(y_output[:,0:-1], axis=0) + K.epsilon()         # = TP + FP\n",
    "    true_positives = K.sum(y_true[:,0:-1] * y_output[:,0:-1], axis=0) + K.epsilon()  # = TP\n",
    "        #all with shape (4,)\n",
    "    \n",
    "    precision = true_positives / pred_positives \n",
    "    recall = true_positives / ground_positives\n",
    "        #both = 1 if ground_positives == 0 or pred_positives == 0\n",
    "        #shape (4,)\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "        #still with shape (4,)\n",
    "\n",
    "    weighted_f1 = f1 * ground_positives / K.sum(ground_positives) \n",
    "    weighted_f1 = K.sum(weighted_f1)\n",
    "\n",
    "    \n",
    "    return 1 - weighted_f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nModel\\n\\nhow cropping layer works - https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-cropping-layers-with-keras.md\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "Model\n",
    "\n",
    "how cropping layer works - https://github.com/christianversloot/machine-learning-articles/blob/main/how-to-use-cropping-layers-with-keras.md\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Output:\n",
    "[prob of no sack, prob of sack, time till sack]\n",
    "\n",
    "If predict no sack, doesn't matter what time is (recorded as -1 in training data)\n",
    "'''\n",
    "\n",
    "def createModel(input_shape = (23,7)):\n",
    "    \n",
    "    X = tfl.Input(input_shape)  # define the input to the model\n",
    "    flat = tfl.Flatten(input_shape=(23, 7))(X)     # Flatten to pass into linear layers\n",
    "    d1 = tfl.Dense(50, activation='relu')(flat)\n",
    "    d3 = tfl.Dense(3,activation=None)(d1)\n",
    "    \n",
    "    # have layer (batch_size, 3). Want to take (b, [0,1]) and turn them into probabilities, and keep (b, [2]) as time\n",
    "    # https://datascience.stackexchange.com/questions/86740/how-to-slice-an-input-in-keras\n",
    "    intermediate = tfl.Reshape((3,1), input_shape=(3,))(d3)\n",
    "    \n",
    "    probs = tfl.Cropping1D(cropping=(0,1))(intermediate)\n",
    "    probs = tfl.Reshape((2,), input_shape=(2,1))(probs)\n",
    "    probs = tfl.Activation('softmax')(probs)\n",
    "    \n",
    "    time = tfl.Cropping1D(cropping=(2,0))(intermediate)\n",
    "    time = tfl.Reshape((1,), input_shape=(1,1))(time)\n",
    "    \n",
    "    # concatenate the probabilities and predicted_time_to_sack back into one layer\n",
    "    out = tfl.Concatenate(axis=-1)([probs, time])\n",
    "    \n",
    "    model = Model(inputs=X, outputs=out)        # create model\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 23, 7)]      0           []                               \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 161)          0           ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 50)           8100        ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 3)            153         ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " reshape_6 (Reshape)            (None, 3, 1)         0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " cropping1d_4 (Cropping1D)      (None, 2, 1)         0           ['reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 2)            0           ['cropping1d_4[0][0]']           \n",
      "                                                                                                  \n",
      " cropping1d_5 (Cropping1D)      (None, 1, 1)         0           ['reshape_6[0][0]']              \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 2)            0           ['reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " reshape_8 (Reshape)            (None, 1)            0           ['cropping1d_5[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 3)            0           ['activation_2[0][0]',           \n",
      "                                                                  'reshape_8[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,253\n",
      "Trainable params: 8,253\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = createModel()\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.000001\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPS = 1e-07\n",
    "\n",
    "# Better optimizer\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=LEARNING_RATE,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "scheduled_opt = optimizers.Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    epsilon=EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    epsilon=EPS)\n",
    "\n",
    "model.compile(loss = my_loss, optimizer = scheduled_opt, metrics = [accuracy_metric, bce_metric, mse_metric, recall, precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1537/1537 [==============================] - 4s 3ms/step - loss: 5.5997 - accuracy_metric: 0.2769 - bce_metric: 1.2736 - mse_metric: 4.3244 - recall: 0.7920 - precision: 0.0834 - val_loss: 2.1200 - val_accuracy_metric: 0.2877 - val_bce_metric: 1.2284 - val_mse_metric: 0.8883 - val_recall: 0.1892 - val_precision: 0.0763\n",
      "Epoch 2/3\n",
      "1537/1537 [==============================] - 4s 3ms/step - loss: 5.0889 - accuracy_metric: 0.3178 - bce_metric: 1.1714 - mse_metric: 3.9189 - recall: 0.7434 - precision: 0.0840 - val_loss: 1.9485 - val_accuracy_metric: 0.3323 - val_bce_metric: 1.1250 - val_mse_metric: 0.8203 - val_recall: 0.1755 - val_precision: 0.0756\n",
      "Epoch 3/3\n",
      "1537/1537 [==============================] - 4s 3ms/step - loss: 4.6955 - accuracy_metric: 0.3664 - bce_metric: 1.0687 - mse_metric: 3.6278 - recall: 0.6921 - precision: 0.0846 - val_loss: 1.7994 - val_accuracy_metric: 0.3848 - val_bce_metric: 1.0220 - val_mse_metric: 0.7745 - val_recall: 0.1607 - val_precision: 0.0762\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 3\n",
    "history = model.fit(x_train[:,:,4:], y_train, epochs=NUM_EPOCHS, batch_size=128, validation_data=(x_val[:,:,4:], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of training plays with no sack = 0.919\n"
     ]
    }
   ],
   "source": [
    "train_no_sack = np.round(np.sum(y_train[:,0])/len(y_train), 3)\n",
    "print(f\"Percentage of training plays with no sack = {train_no_sack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 170ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9783481 , 0.02165189, 3.104981  ],\n",
       "       [0.89377475, 0.10622519, 3.2740505 ],\n",
       "       [0.688783  , 0.31121704, 0.719149  ],\n",
       "       [0.95938665, 0.04061344, 1.6758628 ],\n",
       "       [0.9656645 , 0.03433549, 1.8511863 ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_train[0:5,:,4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(history.history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy_metric</th>\n",
       "      <th>bce_metric</th>\n",
       "      <th>mse_metric</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy_metric</th>\n",
       "      <th>val_bce_metric</th>\n",
       "      <th>val_mse_metric</th>\n",
       "      <th>val_recall</th>\n",
       "      <th>val_precision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.72843</td>\n",
       "      <td>0.514172</td>\n",
       "      <td>0.824179</td>\n",
       "      <td>5.20774</td>\n",
       "      <td>0.492617</td>\n",
       "      <td>0.082449</td>\n",
       "      <td>-0.822297</td>\n",
       "      <td>0.566703</td>\n",
       "      <td>0.739049</td>\n",
       "      <td>1.090825</td>\n",
       "      <td>0.110353</td>\n",
       "      <td>0.076884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  accuracy_metric  bce_metric  mse_metric    recall  precision  \\\n",
       "0 -0.72843         0.514172    0.824179     5.20774  0.492617   0.082449   \n",
       "\n",
       "   val_loss  val_accuracy_metric  val_bce_metric  val_mse_metric  val_recall  \\\n",
       "0 -0.822297             0.566703        0.739049        1.090825    0.110353   \n",
       "\n",
       "   val_precision  \n",
       "0       0.076884  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of validation plays with no sack = 0.924\n"
     ]
    }
   ],
   "source": [
    "num_no_sack = np.round(np.sum(y_val[:,0])/len(y_val), 3)\n",
    "print(f\"Percentage of validation plays with no sack = {num_no_sack}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317/1317 - 2s - loss: 1.4525 - accuracy_metric: 0.3842 - bce_metric: 1.0228 - mse_metric: 0.4294 - recall: 0.0788 - precision: 0.0752 - 2s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "val_loss, cat_acc, val_bce, val_mse, val_recall, val_precision = model.evaluate(x_val[:,:,4:], y_val, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss = 1.4524977207183838\n",
      "categorical accuracy = 0.38421154022216797\n",
      "val_bce = 1.022835373878479\n",
      "val_mse = 0.42941030859947205\n",
      "val_recall = 0.07880528271198273\n",
      "val_precision = 0.07517759501934052\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"val loss = {val_loss}\")\n",
    "print(f\"categorical accuracy = {cat_acc}\")\n",
    "print(f\"val_bce = {val_bce}\")\n",
    "print(f\"val_mse = {val_mse}\")\n",
    "print(f\"val_recall = {val_recall}\")\n",
    "print(f\"val_precision = {val_precision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317/1317 [==============================] - 3s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8433075 , 0.89811885, 0.89859354, ..., 0.47393072, 0.47523332,\n",
       "       0.56478333], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_val[:,:,4:])[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kdnuggets.com/2021/02/saving-loading-models-tensorflow.html\n",
    "\n",
    "model_string = f\"models/fifth_model/weights_epochs{NUM_EPOCHS}\"\n",
    "model.save_weights(model_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Jun  8 2022, 16:11:56) \n[Clang 13.1.6 (clang-1316.0.21.2)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "30db82d8cee61bfe28cec0db433cf9aa423106e927889be025c2bedcf384d61e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
