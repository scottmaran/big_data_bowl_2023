{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 00:23:16.455230: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import createModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load(\"./unnorm_no_shuffle_data/x_train.npy\")\n",
    "y_train = np.load(\"./unnorm_no_shuffle_data/y_train.npy\")\n",
    "x_val = np.load(\"./unnorm_no_shuffle_data/x_val.npy\")\n",
    "y_val= np.load(\"./unnorm_no_shuffle_data/y_val.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Define loss functions\n",
    "'''\n",
    "\n",
    "def my_loss(y_true, y_output):\n",
    "    bce = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "    mse = tf.keras.losses.MeanSquaredError()\n",
    "    return bce(y_true[:,0:-1], y_output[:,0:-1]) + mse(y_true[:,-1], y_output[:,-1])\n",
    "\n",
    "def bce_metric(y_true, y_output):\n",
    "    return K.mean(K.binary_crossentropy(y_true[:,0:-1], y_output[:,0:-1], from_logits=False))\n",
    "\n",
    "def mse_metric(y_true, y_output):\n",
    "    return K.mean(K.square(y_true[:,-1] - y_output[:,-1]), axis=-1)\n",
    "    \n",
    "def accuracy_metric(y_true, y_output):\n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    return K.mean(K.cast(y_true[:,1] == preds, 'float32'))\n",
    "\n",
    "# https://stackoverflow.com/questions/43547402/how-to-calculate-f1-macro-in-keras\n",
    "def recall(y_true, y_output):\n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1], 0, 1)))\n",
    "    false_negatives = K.sum(K.abs(preds - 1) * y_true[:,1]) # turns predicted 0 into 1, multiply by predictions\n",
    "    recall = true_positives / (true_positives + false_negatives  + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "# TP / (TP + FP)\n",
    "def precision(y_true, y_output):\n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1], 0, 1)))\n",
    "    false_positives = K.sum(K.abs(y_true[:,1] - 1) * preds) # turns true y 0 into 1, multiply by predictions\n",
    "    precision = true_positives / (true_positives + false_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def dice_loss(y_true, y_output):\n",
    "    # https://datascience.stackexchange.com/questions/66581/is-it-possible-to-make-f1-score-differentiable-and-use-it-directly-as-a-loss-fun\n",
    "    num = 2*K.sum(y_output[:,1] * y_true[:,1])\n",
    "    denom = K.sum(y_output[:,1]) + K.sum(y_true[:,1])\n",
    "    return 1 - (num/denom)\n",
    "    \n",
    "\n",
    "def f1_loss(y_true, y_output):\n",
    "    \n",
    "    preds = K.cast(K.argmax(y_output[:,0:-1], axis=-1), 'float32')\n",
    "    true_positives = K.sum(K.round(K.clip(y_true[:,1], 0, 1)))\n",
    "    false_positives = K.sum((y_true[:,1] - 1) * -preds) # if y=0, p=1, then -1*-1=1\n",
    "    false_negatives = K.sum((preds - 1) *-y_true[:,1]) # if p=0, y=1, then -1*-1=1\n",
    "    \n",
    "    rec = true_positives / (true_positives + false_negatives  + K.epsilon())\n",
    "    prec = true_positives / (true_positives + false_positives + K.epsilon())\n",
    "    \n",
    "    f1 = 2 * (prec * rec) / (prec + rec + K.epsilon())\n",
    "    \n",
    "    return 1 - f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 00:23:24.655633: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = createModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.000001\n",
    "BETA_1 = 0.9\n",
    "BETA_2 = 0.999\n",
    "EPS = 1e-07\n",
    "\n",
    "# Better optimizer\n",
    "lr_schedule = optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=LEARNING_RATE,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "scheduled_opt = optimizers.Adam(\n",
    "    learning_rate=lr_schedule,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    epsilon=EPS)\n",
    "\n",
    "opt = optimizers.Adam(\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    beta_1=BETA_1,\n",
    "    beta_2=BETA_2,\n",
    "    epsilon=EPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = dice_loss, optimizer = scheduled_opt, metrics = [accuracy_metric, bce_metric, mse_metric, recall, precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1537/1537 [==============================] - 6s 3ms/step - loss: 0.8499 - accuracy_metric: 0.1488 - bce_metric: 12.8426 - mse_metric: 18861.4258 - recall: 0.9425 - precision: 0.0876 - val_loss: 0.8859 - val_accuracy_metric: 0.1596 - val_bce_metric: 12.6665 - val_mse_metric: 18702.5566 - val_recall: 0.2580 - val_precision: 0.0829\n",
      "Epoch 2/3\n",
      "1537/1537 [==============================] - 4s 2ms/step - loss: 0.8499 - accuracy_metric: 0.1492 - bce_metric: 12.8387 - mse_metric: 18907.5332 - recall: 0.9418 - precision: 0.0877 - val_loss: 0.8859 - val_accuracy_metric: 0.1567 - val_bce_metric: 12.7133 - val_mse_metric: 18717.5039 - val_recall: 0.2588 - val_precision: 0.0826\n",
      "Epoch 3/3\n",
      "1537/1537 [==============================] - 4s 3ms/step - loss: 0.8499 - accuracy_metric: 0.1466 - bce_metric: 12.8819 - mse_metric: 18895.5273 - recall: 0.9435 - precision: 0.0874 - val_loss: 0.8859 - val_accuracy_metric: 0.1559 - val_bce_metric: 12.7300 - val_mse_metric: 18722.9766 - val_recall: 0.2592 - val_precision: 0.0825\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 3\n",
    "history = model.fit(x_train[:,:,4:], y_train, epochs=NUM_EPOCHS, batch_size=128, validation_data=(x_val[:,:,4:], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_string = f\"models/dice_checked_data_model/weights_epochs{NUM_EPOCHS}\"\n",
    "model.save_weights(model_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdb_2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "64e913be5900ee3bfd48533456727a82d0e0b84d6c12de93770bb09b0509b267"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
